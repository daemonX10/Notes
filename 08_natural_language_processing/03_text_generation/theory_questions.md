# Text Generation (Seq2Seq, Translation, QA, Summarization) - Theory Questions

## Core Questions

## Question 1
**What is the encoder-decoder architecture and how does it enable sequence-to-sequence learning?**
**Answer:** _To be filled_

---

## Question 2
**Explain the attention mechanism in seq2seq models. Why was it a breakthrough?**
**Answer:** _To be filled_

---

## Question 3
**What is the Transformer architecture? Explain self-attention and multi-head attention.**
**Answer:** _To be filled_

---

## Question 4
**What is beam search decoding and how does it compare to greedy and sampling methods?**
**Answer:** _To be filled_

---

## Question 5
**Explain BLEU score and its limitations for evaluating machine translation.**
**Answer:** _To be filled_

---

## Question 6
**What is the difference between extractive and abstractive summarization?**
**Answer:** _To be filled_

---

## Question 7
**How does reading comprehension QA (SQuAD-style) differ from open-domain QA?**
**Answer:** _To be filled_

---

## Question 8
**What is retrieval-augmented generation (RAG) and why is it important for QA?**
**Answer:** _To be filled_

---

## Question 9
**Explain the teacher forcing technique in training seq2seq models.**
**Answer:** _To be filled_

---

## Question 10
**What are the key evaluation metrics for summarization (ROUGE, BERTScore, factual consistency)?**
**Answer:** _To be filled_

---

## Interview Questions

## Question 11
**How do you handle sequence generation for tasks with extreme input/output length disparities?**
**Answer:** _To be filled_

---

## Question 12
**What techniques prevent repetition and improve diversity in text generation?**
**Answer:** _To be filled_

---

## Question 13
**How do you implement controllable text generation (style, length, tone)?**
**Answer:** _To be filled_

---

## Question 14
**What are the challenges of machine translation for low-resource language pairs?**
**Answer:** _To be filled_

---

## Question 15
**How do you handle domain adaptation in neural machine translation?**
**Answer:** _To be filled_

---

## Question 16
**What techniques work best for real-time/simultaneous machine translation?**
**Answer:** _To be filled_

---

## Question 17
**How do you preserve named entities and technical terms during translation?**
**Answer:** _To be filled_

---

## Question 18
**What is back-translation and how does it help with data augmentation for NMT?**
**Answer:** _To be filled_

---

## Question 19
**How do multilingual translation models (mBART, M2M-100) work?**
**Answer:** _To be filled_

---

## Question 20
**What approaches handle idiomatic expressions and cultural references in translation?**
**Answer:** _To be filled_

---

## Question 21
**How do you design QA systems that handle multi-hop reasoning across documents?**
**Answer:** _To be filled_

---

## Question 22
**What techniques help QA systems know when they don't know the answer?**
**Answer:** _To be filled_

---

## Question 23
**How do you implement conversational QA with context tracking across turns?**
**Answer:** _To be filled_

---

## Question 24
**What is the role of knowledge graphs in question answering systems?**
**Answer:** _To be filled_

---

## Question 25
**How do you handle questions requiring numerical reasoning or table understanding?**
**Answer:** _To be filled_

---

## Question 26
**What is dense passage retrieval (DPR) and how does it improve open-domain QA?**
**Answer:** _To be filled_

---

## Question 27
**How do you balance faithfulness vs fluency in abstractive summarization?**
**Answer:** _To be filled_

---

## Question 28
**What is the hallucination problem in summarization and how do you mitigate it?**
**Answer:** _To be filled_

---

## Question 29
**How do you implement query-focused summarization for specific information needs?**
**Answer:** _To be filled_

---

## Question 30
**What techniques work for multi-document summarization with conflicting information?**
**Answer:** _To be filled_

---

## Question 31
**How do you control summary length while maintaining coherence and coverage?**
**Answer:** _To be filled_

---

## Question 32
**What is copy mechanism in seq2seq models and when is it useful?**
**Answer:** _To be filled_

---

## Question 33
**How do you implement knowledge distillation for compressing large generation models?**
**Answer:** _To be filled_

---

## Question 34
**What is nucleus (top-p) sampling and how does it improve generation quality?**
**Answer:** _To be filled_

---

## Question 35
**How do you evaluate factual consistency in generated text?**
**Answer:** _To be filled_

---

## Question 36
**What is curriculum learning and how does it help train seq2seq models?**
**Answer:** _To be filled_

---

## Question 37
**How do you handle code generation and code summarization tasks?**
**Answer:** _To be filled_

---

## Question 38
**What techniques improve translation quality for morphologically rich languages?**
**Answer:** _To be filled_

---

## Question 39
**How do you implement hybrid extractive-abstractive summarization?**
**Answer:** _To be filled_

---

## Question 40
**What is cross-lingual summarization and what challenges does it present?**
**Answer:** _To be filled_

---

## Question 41
**How do you handle long document summarization that exceeds context limits?**
**Answer:** _To be filled_

---

## Question 42
**What is the exposure bias problem in seq2seq training and how do you address it?**
**Answer:** _To be filled_

---

## Question 43
**How do you implement real-time QA with low latency requirements?**
**Answer:** _To be filled_

---

## Question 44
**What role do pre-trained language models (T5, BART, GPT) play in text generation tasks?**
**Answer:** _To be filled_

---

## Question 45
**How do you fine-tune large language models for specific generation tasks efficiently (LoRA, adapters)?**
**Answer:** _To be filled_

---

## Question 46
**What is RLHF (Reinforcement Learning from Human Feedback) and how does it improve generation?**
**Answer:** _To be filled_

---

## Question 47
**How do you handle bias and fairness issues in text generation systems?**
**Answer:** _To be filled_

---

## Question 48
**What are the key differences between autoregressive and non-autoregressive generation?**
**Answer:** _To be filled_

---

## Question 49
**How do you build production-ready generation systems (caching, batching, optimization)?**
**Answer:** _To be filled_

---

## Question 50
**What is prompt engineering for generation tasks and how do in-context learning approaches work?**
**Answer:** _To be filled_

---
